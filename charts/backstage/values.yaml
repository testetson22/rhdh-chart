nameOverride: developer-hub
global:
  dynamic:
    # -- Array of YAML files listing dynamic plugins to include with those listed in the `plugins` field.
    # Relative paths are resolved from the working directory of the initContainer that will install the plugins (`/opt/app-root/src`).
    includes:
      # -- List of dynamic plugins included inside the `janus-idp/backstage-showcase` container image, some of which are disabled by default.
      # This file ONLY works with the `janus-idp/backstage-showcase` container image.
      - "dynamic-plugins.default.yaml"

    # -- List of dynamic plugins, possibly overriding the plugins listed in `includes` files.
    # Every item defines the plugin `package` as a [NPM package spec](https://docs.npmjs.com/cli/v10/using-npm/package-spec),
    # an optional `pluginConfig` with plugin-specific backstage configuration, and an optional `disabled` flag to disable/enable a plugin
    # listed in `includes` files. It also includes an `integrity` field that is used to verify the plugin package [integrity](https://w3c.github.io/webappsec-subresource-integrity/#integrity-metadata-description).
    plugins: []

  # -- Shorthand for users who do not want to specify a custom HOSTNAME. Used ONLY with the DEFAULT upstream.backstage.appConfig value and with OCP Route enabled.
  clusterRouterBase: "apps.example.com"
  # -- Custom hostname shorthand, overrides `global.clusterRouterBase`, `upstream.ingress.host`, `route.host`, and url values in `upstream.backstage.appConfig`.
  host: ""
  # -- Enable service authentication within Backstage instance
  auth:
    # -- Backend service to service authentication
    # <br /> Ref: https://backstage.io/docs/auth/service-to-service-auth/
    backend:
      # -- Enable backend service to service authentication, unless configured otherwise it generates a secret value
      enabled: true
      # -- Instead of generating a secret value, refer to existing secret
      existingSecret: ""
      # -- Instead of generating a secret value, use the following value
      value: ""

# -- Upstream Backstage [chart configuration](https://github.com/backstage/charts/blob/main/charts/backstage/values.yaml)
# @default -- Use Openshift compatible settings
upstream:
  nameOverride: developer-hub
  backstage:
    image:
      registry: quay.io
      repository: rhdh/rhdh-hub-rhel9
      tag: latest
    command: []
    # FIXME (tumido): USE POSTGRES_PASSWORD and POSTGRES_USER instead of POSTGRES_ADMIN_PASSWORD
    # This is a hack. In {fedora,rhel}/postgresql images, regular user is forbidden
    # from creating DBs in runtime. A single DB can be created ahead of time via
    # POSTGRESQL_DATABASE env variable (in this case via
    # upstream.postgresql.primary.extraEnvVars value), but this doesn't allow us to
    # create multiple DBs. Since Backstage requires by default 5 different DBs, we
    # can't accommodate that properly.
    appConfig:
      auth:
        providers: {}
      app:
        # Please update to match host in case you don't want to configure hostname via `global.clusterRouterBase` or `global.host` if not deploying on an openshift cluster.
        baseUrl: 'https://{{- include "janus-idp.hostname" . }}'
      backend:
        baseUrl: 'https://{{- include "janus-idp.hostname" . }}'
        cors:
          origin: 'https://{{- include "janus-idp.hostname" . }}'
        database:
          connection:
            password: ${POSTGRESQL_ADMIN_PASSWORD}
            user: postgres
        auth:
          externalAccess:
            - type: legacy
              options:
                subject: legacy-default-config
                secret: ${BACKEND_SECRET}
    containerSecurityContext:
      readOnlyRootFilesystem: true
      allowPrivilegeEscalation: false
      capabilities:
        drop: ["ALL"]
      runAsNonRoot: true
      seccompProfile:
        type: "RuntimeDefault"
    resources:
      requests:
        cpu: 250m
        memory: 1Gi
      limits:
        cpu: 1000m
        memory: 2.5Gi
        ephemeral-storage: 5Gi
    startupProbe:
      # This gives enough time upon container startup before the liveness and readiness probes are triggered.
      # Giving (120s = initialDelaySeconds + failureThreshold * periodSeconds) to account for the worst case scenario.
      httpGet:
        path: /.backstage/health/v1/liveness
        port: backend
        scheme: HTTP
      initialDelaySeconds: 30
      timeoutSeconds: 4
      periodSeconds: 20
      successThreshold: 1
      failureThreshold: 3
    readinessProbe:
      failureThreshold: 3
      httpGet:
        path: /.backstage/health/v1/readiness
        port: backend
        scheme: HTTP
      # Both liveness and readiness probes won't be triggered until the startup probe is successful.
      # The startup probe is already configured to give enough time for the application to be started.
      # So removing the additional delay here allows the readiness probe to be checked right away after the startup probe,
      # which helps make the application available faster to the end-user.
      # initialDelaySeconds: 30
      periodSeconds: 10
      successThreshold: 2
      timeoutSeconds: 4
    livenessProbe:
      failureThreshold: 3
      httpGet:
        path: /.backstage/health/v1/liveness
        port: backend
        scheme: HTTP
      # Both liveness and readiness probes won't be triggered until the startup probe is successful.
      # The startup probe is already configured to give enough time for the application to be started.
      # So removing the additional delay here allows the liveness probe to be checked right away after the startup probe,
      # which helps make the application available faster to the end-user.
      # initialDelaySeconds: 60
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 4
    extraEnvVars:
      - name: BACKEND_SECRET
        valueFrom:
          secretKeyRef:
            key: backend-secret
            name: '{{ include "janus-idp.backend-secret-name" $ }}'
      - name: POSTGRESQL_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            key: postgres-password
            name: '{{- include "janus-idp.postgresql.secretName" . }}'
    args:
      # This additional `app-config`` file is generated by the initContainer below, and contains the merged configuration of installed dynamic plugins.
      - "--config"
      - dynamic-plugins-root/app-config.dynamic-plugins.yaml
    extraVolumeMounts:
      # The initContainer below will install dynamic plugins in this volume mount.
      - name: dynamic-plugins-root
        mountPath: /opt/app-root/src/dynamic-plugins-root
      - name: temp
        mountPath: /tmp
    extraVolumes:
      # -- Ephemeral volume that will contain the dynamic plugins installed by the initContainer below at start.
      - name: dynamic-plugins-root
        ephemeral:
          volumeClaimTemplate:
            spec:
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  # -- Size of the volume that will contain the dynamic plugins. It should be large enough to contain all the plugins.
                  storage: 5Gi
      # Volume that will expose the `dynamic-plugins.yaml` file from the `dynamic-plugins` config map.
      # The `dynamic-plugins` config map is created by the helm chart from the content of the `global.dynamic` field.
      - name: dynamic-plugins
        configMap:
          defaultMode: 420
          name: '{{ printf "%s-dynamic-plugins" .Release.Name }}'
          optional: true
      # Optional volume that allows exposing the `.npmrc` file (through a `dynamic-plugins-npmrc` secret)
      # to be used when running `npm pack` during the dynamic plugins installation by the initContainer.
      - name: dynamic-plugins-npmrc
        secret:
          defaultMode: 420
          optional: true
          secretName: '{{ printf "%s-dynamic-plugins-npmrc" .Release.Name }}'
      # Optional volume that allows adding a container registry `auth.json` file (through a `dynamic-plugins-registry-auth` secret)
      # to be used when installing plugins from secure container registries during the dynamic plugins installation by the initContainer.
      - name: dynamic-plugins-registry-auth
        secret:
          defaultMode: 416
          optional: true
          secretName: '{{ printf "%s-dynamic-plugins-registry-auth" .Release.Name }}'
      - name: npmcacache
        emptyDir: {}
      - name: temp
        emptyDir: {}
    initContainers:
      - name: install-dynamic-plugins
        resources:
          requests:
            cpu: 250m
            memory: 256Mi
          limits:
            cpu: 1000m
            memory: 2.5Gi
            ephemeral-storage: 5Gi
        securityContext:
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
          runAsNonRoot: true
          seccompProfile:
            type: "RuntimeDefault"
        # -- Image used by the initContainer to install dynamic plugins into the `dynamic-plugins-root` volume mount.
        # It could be replaced by a custom image based on this one.
        # @default -- `quay.io/janus-idp/backstage-showcase:latest`
        image: '{{ include "backstage.image" . }}'
        command:
          - ./install-dynamic-plugins.sh
          - /dynamic-plugins-root
        env:
          - name: NPM_CONFIG_USERCONFIG
            value: /opt/app-root/src/.npmrc.dynamic-plugins
            # This following variable is required for orchestrator to startup properly.
          - name: MAX_ENTRY_SIZE
            value: "30000000"
        imagePullPolicy: Always
        volumeMounts:
          - mountPath: /dynamic-plugins-root
            name: dynamic-plugins-root
          - mountPath: /opt/app-root/src/dynamic-plugins.yaml
            name: dynamic-plugins
            readOnly: true
            subPath: dynamic-plugins.yaml
          - mountPath: /opt/app-root/src/.npmrc.dynamic-plugins
            name: dynamic-plugins-npmrc
            readOnly: true
            subPath: .npmrc
          - mountPath: /opt/app-root/src/.config/containers
            name: dynamic-plugins-registry-auth
            readOnly: true
          - mountPath: /opt/app-root/src/.npm/_cacache
            name: npmcacache
          - name: temp
            mountPath: /tmp
        workingDir: /opt/app-root/src
    installDir: /opt/app-root/src
    podAnnotations:
      checksum/dynamic-plugins: >-
        {{- include "common.tplvalues.render" ( dict "value"
        .Values.global.dynamic "context" $) | sha256sum }}
  ingress:
    host: "{{ .Values.global.host }}"
  metrics:
    serviceMonitor:
      enabled: false
      path: /metrics
      port: http-metrics
  postgresql:
    enabled: true
    postgresqlDataDir: /var/lib/pgsql/data/userdata
    serviceBindings:
      enabled: true
    image:
      registry: quay.io
      repository: fedora/postgresql-15
      tag: latest
    auth:
      secretKeys:
        adminPasswordKey: postgres-password
        userPasswordKey: password
    primary:
      # TODO: https://issues.redhat.com/browse/RHIDP-2645
      podSecurityContext:
        enabled: false
      containerSecurityContext:
        enabled: false
        allowPrivilegeEscalation: false
        capabilities:
          drop:
            - ALL
      resources:
        requests:
          cpu: 250m
          memory: 256Mi
        limits:
          cpu: 250m
          memory: 1024Mi
          ephemeral-storage: 20Mi
      persistence:
        enabled: true
        size: 1Gi
        mountPath: /var/lib/pgsql/data
      extraEnvVars:
        - name: POSTGRESQL_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              key: postgres-password
              name: '{{- include "postgresql.v1.secretName" . }}'
  service:
    extraPorts:
      - name: http-metrics
        port: 9464
        targetPort: 9464

# -- OpenShift Route parameters
route:
  # -- Route specific annotations
  annotations: {}

  # -- Enable the creation of the route resource
  enabled: true

  # -- Set the host attribute to a custom value. If not set, OpenShift will generate it, please make sure to match your baseUrl
  host: "{{ .Values.global.host }}"

  # -- Path that the router watches for, to route traffic for to the service.
  path: "/"

  # -- Wildcard policy if any for the route. Currently only 'Subdomain' or 'None' is allowed.
  wildcardPolicy: None

  # -- Route TLS parameters
  # <br /> Ref: https://docs.openshift.com/container-platform/4.9/networking/routes/secured-routes.html
  tls:
    # -- Enable TLS configuration for the host defined at `route.host` parameter
    enabled: true

    # -- Specify TLS termination.
    termination: "edge"

    # -- Certificate contents
    certificate: ""

    # -- Key file contents
    key: ""

    # -- Cert authority certificate contents. Optional
    caCertificate: ""

    # -- Contents of the ca certificate of the final destination.
    # <br /> When using reencrypt termination this file should be provided in order to have routers use it for health checks on the secure connection. If this field is not specified, the router may provide its own destination CA and perform hostname validation using the short service name (service.namespace.svc), which allows infrastructure generated certificates to automatically verify.
    destinationCACertificate: ""

    # --  Indicates the desired behavior for insecure connections to a route.
    # <br /> While each router may make its own decisions on which ports to expose, this is normally port 80. The only valid values are None, Redirect, or empty for disabled.
    insecureEdgeTerminationPolicy: "Redirect"

# -- Test pod parameters
test:
  # -- Whether to enable the test-connection pod used for testing the Release using `helm test`.
  enabled: true

  image:
    # -- Test connection pod image registry
    registry: quay.io

    # -- Test connection pod image repository. Note that the image needs to have both the `sh` and `curl` binaries in it.
    repository: curl/curl

    # -- Test connection pod image tag. Note that the image needs to have both the `sh` and `curl` binaries in it.
    tag: latest

  # -- Whether to inject a fake dynamic plugins npmrc secret.
  # <br />See RHDHBUGS-1893 and RHDHBUGS-1464 for the motivation behind this.
  # <br />This is only used for testing purposes and should not be used in production.
  # <br />Only relevant when `test.enabled` field is set to `true`.
  injectTestNpmrcSecret: false

orchestrator:
  enabled: false
  serverlessLogicOperator:
    enabled: true
  serverlessOperator:
    enabled: true
  sonataflowPlatform:
    monitoring:
      enabled: true
    eventing:
      broker:
        name: ""
        namespace: ""
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    # -- Secret name for the user-created secret to connect an external DB
    externalDBsecretRef: ""

    # -- Name for the user-configured external Database
    externalDBName: ""

    # -- Host for the user-configured external Database
    externalDBHost: ""

    # -- Port for the user-configured external Database
    externalDBPort: ""

    # -- Image for the init container used by the create-db job
    initContainerImage: "{{ .Values.upstream.postgresql.image.registry }}/{{ .Values.upstream.postgresql.image.repository }}:{{ .Values.upstream.postgresql.image.tag }}"

    # -- Image for the container used by the create-db job
    createDBJobImage: "{{ .Values.upstream.postgresql.image.registry }}/{{ .Values.upstream.postgresql.image.repository }}:{{ .Values.upstream.postgresql.image.tag }}"

  # -- Orchestrator plugins and their configuration
  plugins:
    # RHDHBUGS-1464: Note that the plugins here fetch the packages from their direct HTTP download URLs from the (official) Red Hat NPM Registry.
    # Previously, we were using the "@redhat/plugin@version" form along with injecting a .npmrc Secret to resolve the "@redhat" scope,
    # but this caused conflicting issues with user-provided .npmrc secrets.
    - disabled: false
      package: "https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.6.0.tgz"
      integrity: sha512-Kr55YbuVwEADwGef9o9wyimcgHmiwehPeAtVHa9g2RQYoSPEa6BeOlaPzB6W5Ke3M2bN/0j0XXtpLuvrlXQogA==
      pluginConfig:
        orchestrator:
          dataIndexService:
            url: http://sonataflow-platform-data-index-service.{{ .Release.Namespace }}
    - disabled: false
      package: "https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.6.0.tgz"
      integrity: sha512-fOSJv2PgtD2urKwBM7p9W6gV/0UIHSf4pkZ9V/wQO0eg0Zi5Mys/CL1ba3nO9x9l84MX11UBZ2r7PPVJPrmOtw==
      pluginConfig:
        dynamicPlugins:
          frontend:
            red-hat-developer-hub.backstage-plugin-orchestrator:
              appIcons:
                - importName: OrchestratorIcon
                  name: orchestratorIcon
              dynamicRoutes:
                - importName: OrchestratorPage
                  menuItem:
                    icon: orchestratorIcon
                    text: Orchestrator
                  path: /orchestrator
    - disabled: false
      package: "https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.6.0.tgz"
      integrity: sha512-Bueeix4661fXEnfJ9y31Yw91LXJgw6hJUG7lPVdESCi9VwBCjDB9Rm8u2yPqP8sriwr0OMtKtqD+Odn3LOPyVw==
      pluginConfig:
        orchestrator:
          dataIndexService:
            url: http://sonataflow-platform-data-index-service.{{ .Release.Namespace }}
    - disabled: false
      package: "https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.6.0.tgz"
      integrity: sha512-Tqn6HO21Q1TQ7TFUoRhwBVCtSBzbQYz+OaanzzIB0R24O6YtVx3wR7Chtr5TzC05Vz5GkBO1+FZid8BKpqljgA==
      pluginConfig:
        dynamicPlugins:
          frontend:
            red-hat-developer-hub.backstage-plugin-orchestrator-form-widgets: {}
